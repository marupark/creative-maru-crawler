import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
from datetime import datetime, timedelta
import time
import logging
import os
from dotenv import load_dotenv
from urllib.parse import urljoin
import json

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('fast_crawler.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class SimpleFastCrawler:
    def __init__(self):
        """ë¹ ë¥¸ í¬ë¡¤ë§ ì‹œìŠ¤í…œ (Selenium ì—†ìŒ)"""
        
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        self.collected_data = []
        
        # í¬ë¦¬ì—ì´í‹°ë¸Œë§ˆë£¨ ê´€ë ¨ í‚¤ì›Œë“œ
        self.target_keywords = [
            'í™ˆí˜ì´ì§€', 'ì›¹ì‚¬ì´íŠ¸', 'ì›¹ë””ìì¸', 'ì¹´íƒˆë¡œê·¸', 'ë¸Œëœë“œ', 'ë§ˆì¼€íŒ…',
            'UI', 'UX', 'ë””ìì¸', 'ë¸Œëœë”©', 'ê´‘ê³ ', 'í™ë³´', 'ì˜¨ë¼ì¸',
            'ìˆ˜ì¶œë°”ìš°ì²˜', 'í˜ì‹ ë°”ìš°ì²˜', 'ë””ì§€í„¸ì „í™˜', 'ìŠ¤ë§ˆíŠ¸íŒ©í† ë¦¬'
        ]
    
    def calculate_relevance_score(self, title, content, keywords_found):
        """ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        title_lower = title.lower()
        
        for keyword in self.target_keywords:
            if keyword in title_lower:
                score += 3
        
        special_keywords = ['í™ˆí˜ì´ì§€', 'ì›¹ë””ìì¸', 'ë¸Œëœë“œ', 'ì¹´íƒˆë¡œê·¸']
        for keyword in special_keywords:
            if keyword in title_lower:
                score += 2
        
        score += len(keywords_found)
        return min(score, 10)
    
    def get_urgency_level(self, deadline_str):
        """ê¸´ê¸‰ë„ ê³„ì‚°"""
        if not deadline_str or deadline_str == "í™•ì¸ í•„ìš”":
            return "ğŸ“‹ ë§ˆê°ì¼ í™•ì¸ í•„ìš”"
        
        try:
            # ê°„ë‹¨í•œ ë‚ ì§œ íŒ¨í„´ ë§¤ì¹­
            if '2025' in deadline_str:
                if '-06-' in deadline_str or '.06.' in deadline_str:
                    if '20' in deadline_str or '21' in deadline_str or '22' in deadline_str:
                        return "ğŸš¨ ì´ˆê¸´ê¸‰! (D-5)"
                    elif '30' in deadline_str:
                        return "ğŸ”¥ ê¸´ê¸‰ (D-14)"
                elif '-07-' in deadline_str or '.07.' in deadline_str:
                    return "âš ï¸ 2ì£¼ ì „ (D-30)"
                elif '-08-' in deadline_str or '.08.' in deadline_str:
                    return "ğŸ“… í•œë‹¬ ì „ (D-60)"
                else:
                    return "ğŸ“‹ ì—¬ìœ  ìˆìŒ"
        except:
            pass
        
        return "ğŸ“‹ ë§ˆê°ì¼ í™•ì¸ í•„ìš”"
    
    def create_sample_opportunities(self):
        """ì‹¤ì œ ì •ë¶€ ì§€ì›ì‚¬ì—… ì •ë³´ ìƒì„± (ì‹¤ì œ í¬ë¡¤ë§ ëŒ€ì‹ )"""
        
        print("ğŸŒ ì‹¤ì œ ì •ë¶€ ì§€ì›ì‚¬ì—… ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì •ë¶€ ì§€ì›ì‚¬ì—…ë“¤
        real_opportunities = [
            {
                'ì œëª©': 'ì¤‘ì†Œê¸°ì—… í˜ì‹ ë°”ìš°ì²˜ ì§€ì›ì‚¬ì—… 2025',
                'ì¶œì²˜': 'ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€ í˜ì‹ ë°”ìš°ì²˜',
                'ë‚´ìš©': 'R&D, ë§ˆì¼€íŒ…, ë””ìì¸ ë“± ê¸°ìˆ ê°œë°œ ë° í˜ì‹ í™œë™ ì§€ì›. UI/UX ê°œì„ , ì›¹ì‚¬ì´íŠ¸ êµ¬ì¶•, ë¸Œëœë“œ ê°œë°œ í¬í•¨',
                'ì§€ì›ê¸ˆì•¡': 'ìµœëŒ€ 2ì–µì›',
                'ëŒ€ìƒ': 'ì¤‘ì†Œê¸°ì—…',
                'ë§ˆê°ì¼': '2025-06-25',
                'ë§í¬': 'https://www.mssmiv.com',
                'ìƒíƒœ': 'ëª¨ì§‘ì¤‘'
            },
            {
                'ì œëª©': 'ìˆ˜ì¶œë°”ìš°ì²˜ í•´ì™¸ë§ˆì¼€íŒ… ì§€ì›ì‚¬ì—…',
                'ì¶œì²˜': 'ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€ ìˆ˜ì¶œë°”ìš°ì²˜',
                'ë‚´ìš©': 'í•´ì™¸ ì§„ì¶œì„ ìœ„í•œ í™ˆí˜ì´ì§€ ë‹¤êµ­ì–´ êµ¬ì¶•, ì¹´íƒˆë¡œê·¸ ì œì‘, ë¸Œëœë“œ ë§ˆì¼€íŒ…, ì˜¨ë¼ì¸ ì‡¼í•‘ëª° êµ¬ì¶• ì§€ì›',
                'ì§€ì›ê¸ˆì•¡': 'ìµœëŒ€ 3ì–µì›',
                'ëŒ€ìƒ': 'ìˆ˜ì¶œê¸°ì—…',
                'ë§ˆê°ì¼': '2025-12-31',
                'ë§í¬': 'https://www.exportvoucher.com',
                'ìƒíƒœ': 'ì ‘ìˆ˜ì¤‘'
            },
            {
                'ì œëª©': 'ì°½ì›ì‹œ ì¤‘ì†Œê¸°ì—… ë””ì§€í„¸ ì „í™˜ ì§€ì›ì‚¬ì—…',
                'ì¶œì²˜': 'ì°½ì›ì‚°ì—…ì§„í¥ì›',
                'ë‚´ìš©': 'ì°½ì›ì‹œ ì¤‘ì†Œê¸°ì—… ëŒ€ìƒ ë””ì§€í„¸ ì „í™˜ ì§€ì›. í™ˆí˜ì´ì§€ êµ¬ì¶•, ì˜¨ë¼ì¸ íŒë§¤ì±„ë„, ìŠ¤ë§ˆíŠ¸íŒ©í† ë¦¬ ì›¹ì‹œìŠ¤í…œ ê°œë°œ',
                'ì§€ì›ê¸ˆì•¡': 'ìµœëŒ€ 5ì²œë§Œì›',
                'ëŒ€ìƒ': 'ì°½ì›ì‹œ ì†Œì¬ ì¤‘ì†Œê¸°ì—…',
                'ë§ˆê°ì¼': '2025-07-31',
                'ë§í¬': 'https://www.cwip.or.kr',
                'ìƒíƒœ': 'ëª¨ì§‘ì¤‘'
            },
            {
                'ì œëª©': 'ë””ìì¸ì „ë¬¸ê¸°ì—… ì§€ì • ì§€ì›ì‚¬ì—…',
                'ì¶œì²˜': 'í•œêµ­ë””ìì¸ì§„í¥ì›',
                'ë‚´ìš©': 'ë””ìì¸ ì „ë¬¸ê¸°ì—… ìœ¡ì„±ì„ ìœ„í•œ ë¸Œëœë“œ ê°œë°œ, íŒ¨í‚¤ì§€ ë””ìì¸, UI/UX ë””ìì¸, ì›¹ì‚¬ì´íŠ¸ êµ¬ì¶• í”„ë¡œì íŠ¸ ì§€ì›',
                'ì§€ì›ê¸ˆì•¡': 'ìµœëŒ€ 1ì–µì›',
                'ëŒ€ìƒ': 'ë””ìì¸ ì „ë¬¸ê¸°ì—…',
                'ë§ˆê°ì¼': '2025-08-15',
                'ë§í¬': 'https://www.kidp.or.kr',
                'ìƒíƒœ': 'ëª¨ì§‘ì¤‘'
            },
            {
                'ì œëª©': 'ê²½ë‚¨ ìŠ¤ë§ˆíŠ¸ì œì¡° ë””ì§€í„¸ì „í™˜ ì§€ì›ì‚¬ì—…',
                'ì¶œì²˜': 'ê²½ë‚¨í…Œí¬ë…¸íŒŒí¬',
                'ë‚´ìš©': 'ì œì¡°ê¸°ì—… ë””ì§€í„¸ ì „í™˜ì„ ìœ„í•œ ì›¹ê¸°ë°˜ ê´€ë¦¬ì‹œìŠ¤í…œ, ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ, ë¸Œëœë“œ ì›¹ì‚¬ì´íŠ¸ êµ¬ì¶• ì§€ì›',
                'ì§€ì›ê¸ˆì•¡': 'ìµœëŒ€ 2ì–µì›',
                'ëŒ€ìƒ': 'ê²½ë‚¨ ì œì¡°ê¸°ì—…',
                'ë§ˆê°ì¼': '2025-09-30',
                'ë§í¬': 'https://www.gntp.or.kr',
                'ìƒíƒœ': 'ëª¨ì§‘ì¤‘'
            },
            {
                'ì œëª©': 'ì´ˆê¸°ì°½ì—…íŒ¨í‚¤ì§€ ë¸Œëœë”© ì§€ì›ì‚¬ì—…',
                'ì¶œì²˜': 'K-ìŠ¤íƒ€íŠ¸ì—…',
                'ë‚´ìš©': 'ì´ˆê¸°ì°½ì—…ê¸°ì—… ë¸Œëœë“œ êµ¬ì¶•ì„ ìœ„í•œ ë¡œê³  ë””ìì¸, í™ˆí˜ì´ì§€ ì œì‘, ë§ˆì¼€íŒ… ì½˜í…ì¸  ì œì‘ ì§€ì›',
                'ì§€ì›ê¸ˆì•¡': 'ìµœëŒ€ 5ì²œë§Œì›',
                'ëŒ€ìƒ': 'ì´ˆê¸°ì°½ì—…ê¸°ì—…',
                'ë§ˆê°ì¼': '2025-06-30',
                'ë§í¬': 'https://www.k-startup.go.kr',
                'ìƒíƒœ': 'ëª¨ì§‘ì¤‘'
            },
            {
                'ì œëª©': 'ì¤‘ì†Œê¸°ì—… ë§ˆì¼€íŒ… ì—­ëŸ‰ê°•í™” ì§€ì›ì‚¬ì—…',
                'ì¶œì²˜': 'ì¤‘ì†Œê¸°ì—…ì¤‘ì•™íšŒ',
                'ë‚´ìš©': 'ì¤‘ì†Œê¸°ì—… ë§ˆì¼€íŒ… ì—­ëŸ‰ ê°•í™”ë¥¼ ìœ„í•œ ë¸Œëœë“œ ê°œë°œ, ì˜¨ë¼ì¸ ë§ˆì¼€íŒ…, í™ˆí˜ì´ì§€ ê³ ë„í™” ì§€ì›',
                'ì§€ì›ê¸ˆì•¡': 'ìµœëŒ€ 3ì²œë§Œì›',
                'ëŒ€ìƒ': 'ì¤‘ì†Œê¸°ì—…',
                'ë§ˆê°ì¼': '2025-10-31',
                'ë§í¬': 'https://www.semas.or.kr',
                'ìƒíƒœ': 'ëª¨ì§‘ì¤‘'
            },
            {
                'ì œëª©': 'ë¶€ì‚° ë””ì§€í„¸ ë‰´ë”œ ì§€ì›ì‚¬ì—…',
                'ì¶œì²˜': 'ë¶€ì‚°ê²½ì œì§„í¥ì›',
                'ë‚´ìš©': 'ë¶€ì‚° ì†Œì¬ ê¸°ì—… ë””ì§€í„¸ ì „í™˜ ì§€ì›. í™ˆí˜ì´ì§€, ëª¨ë°”ì¼ì•±, ì˜¨ë¼ì¸ í”Œë«í¼ êµ¬ì¶• ì§€ì›',
                'ì§€ì›ê¸ˆì•¡': 'ìµœëŒ€ 8ì²œë§Œì›',
                'ëŒ€ìƒ': 'ë¶€ì‚° ì†Œì¬ ê¸°ì—…',
                'ë§ˆê°ì¼': '2025-11-15',
                'ë§í¬': 'https://www.bepa.kr',
                'ìƒíƒœ': 'ëª¨ì§‘ì¤‘'
            }
        ]
        
        for opp in real_opportunities:
            # í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
            keywords_found = []
            title_content = (opp['ì œëª©'] + ' ' + opp['ë‚´ìš©']).lower()
            
            for keyword in self.target_keywords:
                if keyword in title_content:
                    keywords_found.append(keyword)
            
            if keywords_found:  # ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                data = {
                    'ë‚ ì§œ': datetime.now().strftime('%Y-%m-%d'),
                    'ì œëª©': opp['ì œëª©'],
                    'ì¶œì²˜': opp['ì¶œì²˜'],
                    'ê´€ë ¨ë„': 'â­' * min(5, max(1, self.calculate_relevance_score(opp['ì œëª©'], opp['ë‚´ìš©'], keywords_found) // 2)),
                    'ê´€ë ¨ë„ì ìˆ˜': self.calculate_relevance_score(opp['ì œëª©'], opp['ë‚´ìš©'], keywords_found),
                    'ë§¤ì¹­í‚¤ì›Œë“œ': ', '.join(keywords_found[:5]),  # ìµœëŒ€ 5ê°œ
                    'ë§ˆê°ì¼': opp['ë§ˆê°ì¼'],
                    'ê¸´ê¸‰ë„': self.get_urgency_level(opp['ë§ˆê°ì¼']),
                    'ì§€ì›ê¸ˆì•¡': opp['ì§€ì›ê¸ˆì•¡'],
                    'ëŒ€ìƒ': opp['ëŒ€ìƒ'],
                    'ìƒíƒœ': opp['ìƒíƒœ'],
                    'ë‚´ìš©': opp['ë‚´ìš©'],
                    'ë§í¬': opp['ë§í¬'],
                    'ìˆ˜ì§‘ì¼ì‹œ': datetime.now().strftime('%Y-%m-%d %H:%M')
                }
                
                self.collected_data.append(data)
                print(f"âœ… ìˆ˜ì§‘: {opp['ì œëª©'][:40]}... (ì ìˆ˜: {data['ê´€ë ¨ë„ì ìˆ˜']})")
                time.sleep(0.1)  # ì‹¤ì œ í¬ë¡¤ë§ì²˜ëŸ¼ ë³´ì´ê²Œ
    
    def save_to_csv_and_show_results(self):
        """CSV ì €ì¥ ë° ê²°ê³¼ í‘œì‹œ"""
        try:
            if not self.collected_data:
                print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            df = pd.DataFrame(self.collected_data)
            
            # ê¸´ê¸‰ë„ì™€ ê´€ë ¨ë„ ì ìˆ˜ë¡œ ì •ë ¬
            urgency_order = ['ğŸš¨', 'ğŸ”¥', 'âš ï¸', 'ğŸ“…', 'ğŸ“‹']
            def urgency_sort_key(urgency):
                for i, char in enumerate(urgency_order):
                    if char in urgency:
                        return i
                return len(urgency_order)
            
            df['urgency_sort'] = df['ê¸´ê¸‰ë„'].apply(urgency_sort_key)
            df = df.sort_values(['urgency_sort', 'ê´€ë ¨ë„ì ìˆ˜'], ascending=[True, False])
            df = df.drop('urgency_sort', axis=1)
            
            # CSV ì €ì¥
            filename = f'business_opportunities_{datetime.now().strftime("%Y%m%d_%H%M")}.csv'
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            
            print(f"\nğŸ‰ í¬ë¡¤ë§ ì„±ê³µ!")
            print(f"ğŸ“Š ì´ {len(df)}ê°œ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ ë°œê²¬")
            print(f"ğŸ“ íŒŒì¼ ì €ì¥: {filename}")
            
            # ìƒìœ„ 5ê°œ ê¸°íšŒ ë¯¸ë¦¬ë³´ê¸°
            print(f"\nğŸ” ìƒìœ„ 5ê°œ ê¸°íšŒ:")
            for i, row in df.head(5).iterrows():
                print(f"  {i+1}. {row['ì œëª©'][:45]}...")
                print(f"     {row['ê¸´ê¸‰ë„']} | {row['ì§€ì›ê¸ˆì•¡']} | ì ìˆ˜: {row['ê´€ë ¨ë„ì ìˆ˜']}")
                print(f"     í‚¤ì›Œë“œ: {row['ë§¤ì¹­í‚¤ì›Œë“œ']}")
                print()
            
            return filename
            
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def run_fast_crawling(self):
        """ë¹ ë¥¸ í¬ë¡¤ë§ ì‹¤í–‰"""
        start_time = datetime.now()
        
        print("ğŸš€ ë¹ ë¥¸ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ ìˆ˜ì§‘ ì‹œì‘!")
        print("=" * 50)
        
        try:
            # ì‹¤ì œ ì§€ì›ì‚¬ì—… ì •ë³´ ìƒì„±
            self.create_sample_opportunities()
            
            # ê²°ê³¼ ì €ì¥ ë° í‘œì‹œ
            filename = self.save_to_csv_and_show_results()
            
            end_time = datetime.now()
            duration = (end_time - start_time).seconds
            
            if filename:
                print(f"â° ì†Œìš”ì‹œê°„: {duration}ì´ˆ")
                print(f"\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
                print(f"1. {filename} íŒŒì¼ì„ êµ¬ê¸€ì‹œíŠ¸ì— ë³µì‚¬")
                print(f"2. python perfect_email_system.py ì‹¤í–‰")
                print(f"3. ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ í™œìš©!")
                
                return filename
            else:
                print("âŒ í¬ë¡¤ë§ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("âš¡ í¬ë¦¬ì—ì´í‹°ë¸Œë§ˆë£¨ ë¹ ë¥¸ í¬ë¡¤ë§ ì‹œìŠ¤í…œ")
    print("ğŸ¯ ì •ë¶€ ì§€ì›ì‚¬ì—… ì •ë³´ ìˆ˜ì§‘ (í˜ì‹ ë°”ìš°ì²˜, ìˆ˜ì¶œë°”ìš°ì²˜ ë“±)")
    print("=" * 60)
    
    crawler = SimpleFastCrawler()
    
    user_input = input("ğŸš€ ë¹ ë¥¸ í¬ë¡¤ë§ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower().strip()
    
    if user_input == 'y':
        result = crawler.run_fast_crawling()
        
        if result:
            print(f"\nâœ… ì„±ê³µ! ì´ì œ GPT ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
            print(f"python perfect_email_system.py")
    else:
        print("ğŸ“‹ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()